---
title: "Biostat 203B Homework 5"
subtitle: Due Mar 22 @ 11:59PM
author: "Zijie Chen 305975150"
format:
  html:
    theme: cosmo
    embed-resources: true
    number-sections: false
    toc: true
    toc-depth: 4
    toc-location: left
    code-fold: false
---

## Predicting ICU duration

Using the ICU cohort `mimiciv_icu_cohort.rds` you built in Homework 4, develop at least three machine learning approaches (logistic regression with enet regularization, random forest, boosting, SVM, MLP, etc) plus a model stacking approach for predicting whether a patient's ICU stay will be longer than 2 days. You should use the `los_long` variable as the outcome. You algorithms can use patient demographic information (gender, age at ICU `intime`, marital status, race), ICU admission information (first care unit), the last lab measurements before the ICU stay, and first vital measurements during ICU stay as features. You are welcome to use any feature engineering techniques you think are appropriate; but make sure to not use features that are not available at an ICU stay's `intime`. For instance, `last_careunit` cannot be used in your algorithms. 

#1. Data preprocessing and feature engineering.

### Library
```{r}
library(tidyverse)
library(tidymodels)
library(ggplot2)
library(corrplot)
library(ggthemes)
library(naniar)
library(kableExtra)
library(ISLR)
library(ISLR2)
library(glmnet)
library(themis)
library(discrim)
library(corrplot)
library(modeldata)
library(janitor)
library(xgboost)
library(ranger)
library(vip)
library(keras)
library(corrplot)
library(gtsummary)
library(tensorflow)
library(stacks)
tidymodels_prefer()
```

### EDA
```{r}
mimic_icu_cohort <- read_rds("mimic_icu_cohort.rds")
head(mimic_icu_cohort)
dim(mimic_icu_cohort)
colnames(mimic_icu_cohort)
summary_table <- mimic_icu_cohort %>% 
  select(first_careunit, los, admission_type,
         admission_location, discharge_location, insurance, language,
         marital_status, race, hospital_expire_flag, gender,
         dod, Sodium, Chloride, Creatinine, Potassium,
         Glucose, Hematocrit, `White Blood Cells`, Bicarbonate, 
         `Temperature Fahrenheit`, `Non Invasive Blood Pressure diastolic`,
         `Respiratory Rate`, `Non Invasive Blood Pressure systolic`,
         `Heart Rate`, age_intime, los_long) |>
  tbl_summary(by = los_long)
summary_table
colSums(is.na(mimic_icu_cohort))
```
### Feature Engineering

```{r}
#unique(mimic_icu_cohort$admit_provider_id)
```

We only use features that are available at an ICU stay's intime, so we drop 
last_careunit,dod, outtime ,dischitime,discharge_location and also we have 
to remove los because it is a target variable. deathtime, edregtime and 
edouttime are also removed since they have too many missing values. 
I have also dropped admit_provider_id,
since this variable has too many levels and it's simply the id for people who 
admitted the patient. I have also dropped anchor_year_group since it's 
useless since we have already have the anchor_year. 

```{r}
mimiciv_icu_cohort <- mimic_icu_cohort %>%
  select(-c(last_careunit,dod,los,deathtime,
            edregtime,edouttime, discharge_location,
            outtime, dischtime,
            admit_provider_id, anchor_year_group))
```

Factor the factor variables
```{r}
mimiciv_icu_cohort <- mimiciv_icu_cohort %>%
  mutate(los_long = factor(los_long),
         insurance = factor(insurance),
         language = factor(language),
         marital_status = factor(marital_status),
         hospital_expire_flag = factor(hospital_expire_flag),
         gender = factor(gender)
  )
```

To replace spaces with underscores in all column names
```{r}
names(mimiciv_icu_cohort) <- gsub(" ", "_", names(mimiciv_icu_cohort))
```

We also have to convert intime and admittime to a data type that model can process,
I have decided to convert them to a three levels factor with the levels being morning,
afternoon and night.

```{r}
convert_time_to_factor <- function(time_column) {
  sapply(time_column, function(time) {
    hour <- as.integer(format(time, "%H"))
    if (hour >= 5 && hour <= 11) {
      return("Morning")
    } else if (hour >= 12 && hour <= 17) {
      return("Afternoon")
    } else {
      return("Night")
    }
  }) -> time_factors
  
  return(factor(time_factors, levels = c("Morning", "Afternoon", "Night")))
}

mimiciv_icu_cohort$intime <- convert_time_to_factor(mimiciv_icu_cohort$intime)
mimiciv_icu_cohort$admittime <- convert_time_to_factor(mimiciv_icu_cohort$admittime)
```


#2. Partition data into 50% training set and 50% test set. Stratify partitioning according to `los_long`. For grading purpose, sort the data by `subject_id`, `hadm_id`, and `stay_id` and use the seed `203` for the initial data split. Below is the sample code.
```{r}
#| eval: True
set.seed(203)

# sort
mimiciv_icu_cohort <- mimiciv_icu_cohort %>%
  arrange(subject_id, hadm_id, stay_id)

# Drop the id columns, since they are not useful for modeling
mimiciv_icu_cohort <- mimiciv_icu_cohort %>%
  select(-c(subject_id, hadm_id, stay_id))

data_split <- initial_split(
  mimiciv_icu_cohort, 
  # stratify by los_long
  strata = "los_long", 
  prop = 0.5
  )

Mimic_other <- training(data_split)
dim(Mimic_other)
Mimic_test <- testing(data_split)
dim(Mimic_test)
colSums(is.na(mimiciv_icu_cohort))
```

#3. Train and tune the models using the training set.

### Recipe
There are missing values, since missing values are not too much, I would use mean to impute
the missing values for the numeric variables and knn method for the categorical variables.
As we know, using mean to impute missing values will affect the sample variance. But it also
limits the leverage of missing data.
```{r}
mimic_recipe <-
  recipe(
    los_long ~ .,
    data = Mimic_other
  ) %>%
  step_impute_mean(all_numeric_predictors()) %>%
  step_impute_knn(all_nominal_predictors()) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_zv(all_numeric_predictors()) %>%
  step_normalize(all_numeric_predictors()) %>%
  prep(training = Mimic_other, retain = TRUE)
mimic_recipe %>% bake(Mimic_other)

```

### Model

```{r}
logit_mod <- 
  logistic_reg(
    penalty = tune(), 
    mixture = tune()
  ) %>%
  set_engine("glmnet", standardize = FALSE) %>%
  print()

rf_mod <- 
  rand_forest(
    mode = "classification",
    mtry = tune(),
    trees = tune()
  ) %>%
  set_engine("ranger") %>%
  print()

mlp_mod <- 
  mlp(
    mode = "classification",
    hidden_units = tune(),
    dropout = tune(),
    epochs = 5,
  ) %>%
  set_engine("keras", verbose = 0) %>%
  print()

gb_mod <- 
  boost_tree(
    mode = "classification",
    trees = 200, 
    tree_depth = tune(),
    learn_rate = tune()
  ) %>%
  set_engine("xgboost") %>%
  print()
```

### Workflow

```{r}
logit_wf <- workflow() %>%
  add_recipe(mimic_recipe) %>%
  add_model(logit_mod) %>%
  print()

rf_wf <- workflow() %>%
  add_recipe(mimic_recipe) %>% 
  add_model(rf_mod) %>%
  print()

mlp_wf <- workflow() %>%
  add_recipe(mimic_recipe) %>% 
  add_model(mlp_mod) %>%
  print()

gb_wf <- workflow() %>%
  add_recipe(mimic_recipe) %>% 
  add_model(gb_mod) %>%
  print()
```

### Tuning grid

```{r}
logit_param_grid <- grid_regular(
  penalty(range = c(-6, 3)), 
  mixture(),
  levels = c(100, 5)
  )

rf_param_grid <- grid_regular(
  trees(range = c(100L, 400L)), 
  mtry(range = c(1L, 6L)),
  levels = c(5, 5)
  )

mlp_param_grid <- grid_regular(
  hidden_units(range = c(1, 4)),
  dropout(range = c(0, 0.2)),
  levels = 3
  )

gb_param_grid <- grid_regular(
  tree_depth(range = c(1L, 4L)),
  learn_rate(range = c(-5, 2), trans = log10_trans()),
  levels = c(3, 10)
  )
```

### Cross_validation

```{r}
set.seed(203)
folds <- vfold_cv(Mimic_other, v = 5)
```

#### logistic regression with enet regularization
```{r}
#| eval: True
logit_fit <- 
    tune_grid(
    object = logit_wf, 
    resamples = folds, 
    grid = logit_param_grid,
    control = control_stack_grid()
  )

logit_fit  %>%
  collect_metrics() %>%
  print(width = Inf) %>%
  filter(.metric == "roc_auc") %>%
  ggplot(mapping = aes(x = penalty, y = mean, color = factor(mixture))) +
  geom_point() +
  labs(x = "Penalty", y = "CV AUC") +
  scale_x_log10()

best_logit <- logit_fit %>%
  select_best("roc_auc")
```

#### Random forest
```{r}
#| eval: True
rf_fit <- 
  tune_grid(
    object = rf_wf,
    resamples = folds,
    grid = rf_param_grid,
    control = control_stack_grid()
  )

rf_fit %>%
  collect_metrics() %>%
  print(width = Inf) %>%
  filter(.metric == "roc_auc") %>%
  ggplot(mapping = aes(x = trees, y = mean, color = factor(mtry))) +
  geom_point() + 
  # geom_line() + 
  labs(x = "Num. of Trees", y = "CV AUC")

best_rf <- rf_fit %>%
  select_best("roc_auc")
```

#### MLP
```{r}
#| eval: True
mlp_fit <- mlp_wf %>%
  tune_grid(
    resamples = folds,
    grid = mlp_param_grid,
    metrics = metric_set(roc_auc, accuracy)
  )

mlp_fit %>%
  collect_metrics() %>%
  print(width = Inf) %>%
  filter(.metric == "roc_auc") %>%
  ggplot(mapping = aes(x = dropout, y = mean, color = factor(hidden_units))) +
  geom_point() +
  labs(x = "Dropout Rate", y = "CV AUC") +
  scale_x_log10()

best_mlp <- mlp_fit %>%
  select_best("roc_auc")
```

#### Boosting

```{r}
#| eval: True
gb_fit <- 
  tune_grid(
    object = gb_wf,
    resamples = folds,
    grid = gb_param_grid,
    control = control_stack_grid()
  )

gb_fit %>%
  collect_metrics() %>%
  print(width = Inf) %>%
  filter(.metric == "roc_auc") %>%
  ggplot(mapping = aes(x = learn_rate, y = mean, color = factor(tree_depth))) +
  geom_point() +
  labs(x = "Learning Rate", y = "CV AUC") +
  scale_x_log10()

best_gb <- gb_fit %>%
  select_best("roc_auc")
```

#### Model Stacking

```{r}
#| eval: True

mimic_model_st <-
  stacks() %>%
  add_candidates(logit_fit) %>%
  add_candidates(rf_fit) %>%
  add_candidates(gb_fit) %>%
  blend_predictions(
    penalty = 10^(-6:2),
    metrics = c("roc_auc", "accuracy")
  ) %>%
  fit_members()

autoplot(mimic_model_st)
autoplot(mimic_model_st, type = "weights")
```


### Finalize our model

```{r}
#| eval: True
final_log_wf <- logit_wf %>%
  finalize_workflow(best_logit)

final_log_fit <- 
  final_log_wf %>%
  last_fit(data_split)

final_rf_wf <- rf_wf %>%
  finalize_workflow(best_rf)

final_rf_fit <-
  final_rf_wf %>%
  last_fit(data_split)

final_mlp_wf <- mlp_wf %>%
  finalize_workflow(best_mlp)

final_mlp_fit <-
  final_mlp_wf %>%
  last_fit(data_split)

final_gb_wf <- gb_wf %>%
  finalize_workflow(best_gb)

final_gb_fit <-
  final_gb_wf %>%
  last_fit(data_split)

mimic_pred <- Mimic_test %>%
  bind_cols(predict(mimic_model_st, ., type = "prob"))
```


#4. Compare model classification performance on the test set. Report both the area under ROC curve and accuracy for each machine learning algorithm and the model stacking. Interpret the results. What are the most important features in predicting long ICU stays? How do the models compare in terms of performance and interpretability?


#### logistic regression with enet regularization
```{r}
#| eval: True
final_log_fit %>%
  collect_metrics()
```

#### Random forest
```{r}
#| eval: True
final_rf_fit %>%
  collect_metrics()
```

#### MLP
```{r}
#| eval: True
final_mlp_fit %>%
  collect_metrics()
```

#### Boosting
```{r}
#| eval: True
final_gb_fit %>%
  collect_metrics()
```

#### Model Stacking

```{r}
#| eval: True
yardstick::roc_auc(
  mimic_pred,
  truth = los_long,
  contains(".pred_False")
)
```
